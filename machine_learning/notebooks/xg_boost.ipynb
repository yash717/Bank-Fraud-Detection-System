{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid 'Account_Creation_Date' format. Please ensure it's in YYYY-MM-DD format.\n"
     ]
    },
    {
     "ename": "XGBoostError",
     "evalue": "[17:15:05] C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0fdc6d574b9c0d168-1\\xgboost\\xgboost-ci-windows\\src\\c_api\\c_api.cc:675: DMatrix/Booster has not been initialized or has already been disposed.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Yash\\Desktop\\fraud_detection_project\\machine_learning\\notebooks\\xg_boost.ipynb Cell 1\u001b[0m line \u001b[0;36m7\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Yash/Desktop/fraud_detection_project/machine_learning/notebooks/xg_boost.ipynb#W0sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m new_input \u001b[39m=\u001b[39m preprocess_input(new_input_data)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Yash/Desktop/fraud_detection_project/machine_learning/notebooks/xg_boost.ipynb#W0sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m \u001b[39m# Make predictions using the loaded model\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Yash/Desktop/fraud_detection_project/machine_learning/notebooks/xg_boost.ipynb#W0sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m fraud_prediction \u001b[39m=\u001b[39m loaded_model\u001b[39m.\u001b[39;49mpredict(new_input)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Yash/Desktop/fraud_detection_project/machine_learning/notebooks/xg_boost.ipynb#W0sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFraud Prediction: \u001b[39m\u001b[39m{\u001b[39;00mfraud_prediction\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Yash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\sklearn.py:1525\u001b[0m, in \u001b[0;36mXGBClassifier.predict\u001b[1;34m(self, X, output_margin, ntree_limit, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\n\u001b[0;32m   1516\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   1517\u001b[0m     X: ArrayLike,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1522\u001b[0m     iteration_range: Optional[Tuple[\u001b[39mint\u001b[39m, \u001b[39mint\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1523\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[0;32m   1524\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(verbosity\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbosity):\n\u001b[1;32m-> 1525\u001b[0m         class_probs \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mpredict(\n\u001b[0;32m   1526\u001b[0m             X\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m   1527\u001b[0m             output_margin\u001b[39m=\u001b[39;49moutput_margin,\n\u001b[0;32m   1528\u001b[0m             ntree_limit\u001b[39m=\u001b[39;49mntree_limit,\n\u001b[0;32m   1529\u001b[0m             validate_features\u001b[39m=\u001b[39;49mvalidate_features,\n\u001b[0;32m   1530\u001b[0m             base_margin\u001b[39m=\u001b[39;49mbase_margin,\n\u001b[0;32m   1531\u001b[0m             iteration_range\u001b[39m=\u001b[39;49miteration_range,\n\u001b[0;32m   1532\u001b[0m         )\n\u001b[0;32m   1533\u001b[0m         \u001b[39mif\u001b[39;00m output_margin:\n\u001b[0;32m   1534\u001b[0m             \u001b[39m# If output_margin is active, simply return the scores\u001b[39;00m\n\u001b[0;32m   1535\u001b[0m             \u001b[39mreturn\u001b[39;00m class_probs\n",
      "File \u001b[1;32mc:\\Users\\Yash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\sklearn.py:1139\u001b[0m, in \u001b[0;36mXGBModel.predict\u001b[1;34m(self, X, output_margin, ntree_limit, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[0;32m   1129\u001b[0m         \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1131\u001b[0m test \u001b[39m=\u001b[39m DMatrix(\n\u001b[0;32m   1132\u001b[0m     X,\n\u001b[0;32m   1133\u001b[0m     base_margin\u001b[39m=\u001b[39mbase_margin,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1137\u001b[0m     enable_categorical\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39menable_categorical,\n\u001b[0;32m   1138\u001b[0m )\n\u001b[1;32m-> 1139\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_booster()\u001b[39m.\u001b[39;49mpredict(\n\u001b[0;32m   1140\u001b[0m     data\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m   1141\u001b[0m     iteration_range\u001b[39m=\u001b[39;49miteration_range,\n\u001b[0;32m   1142\u001b[0m     output_margin\u001b[39m=\u001b[39;49moutput_margin,\n\u001b[0;32m   1143\u001b[0m     validate_features\u001b[39m=\u001b[39;49mvalidate_features,\n\u001b[0;32m   1144\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Yash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:2137\u001b[0m, in \u001b[0;36mBooster.predict\u001b[1;34m(self, data, output_margin, ntree_limit, pred_leaf, pred_contribs, approx_contribs, pred_interactions, validate_features, training, iteration_range, strict_shape)\u001b[0m\n\u001b[0;32m   2135\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mExpecting data to be a DMatrix object, got: \u001b[39m\u001b[39m'\u001b[39m, \u001b[39mtype\u001b[39m(data))\n\u001b[0;32m   2136\u001b[0m \u001b[39mif\u001b[39;00m validate_features:\n\u001b[1;32m-> 2137\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_dmatrix_features(data)\n\u001b[0;32m   2138\u001b[0m iteration_range \u001b[39m=\u001b[39m _convert_ntree_limit(\u001b[39mself\u001b[39m, ntree_limit, iteration_range)\n\u001b[0;32m   2139\u001b[0m args \u001b[39m=\u001b[39m {\n\u001b[0;32m   2140\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m0\u001b[39m,\n\u001b[0;32m   2141\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtraining\u001b[39m\u001b[39m\"\u001b[39m: training,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2144\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mstrict_shape\u001b[39m\u001b[39m\"\u001b[39m: strict_shape,\n\u001b[0;32m   2145\u001b[0m }\n",
      "File \u001b[1;32mc:\\Users\\Yash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:2735\u001b[0m, in \u001b[0;36mBooster._validate_dmatrix_features\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   2734\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_validate_dmatrix_features\u001b[39m(\u001b[39mself\u001b[39m, data: DMatrix) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 2735\u001b[0m     \u001b[39mif\u001b[39;00m data\u001b[39m.\u001b[39;49mnum_row() \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   2736\u001b[0m         \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m   2738\u001b[0m     fn \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mfeature_names\n",
      "File \u001b[1;32mc:\\Users\\Yash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:1064\u001b[0m, in \u001b[0;36mDMatrix.num_row\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1062\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Get the number of rows in the DMatrix.\"\"\"\u001b[39;00m\n\u001b[0;32m   1063\u001b[0m ret \u001b[39m=\u001b[39m c_bst_ulong()\n\u001b[1;32m-> 1064\u001b[0m _check_call(_LIB\u001b[39m.\u001b[39;49mXGDMatrixNumRow(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle, ctypes\u001b[39m.\u001b[39;49mbyref(ret)))\n\u001b[0;32m   1065\u001b[0m \u001b[39mreturn\u001b[39;00m ret\u001b[39m.\u001b[39mvalue\n",
      "File \u001b[1;32mc:\\Users\\Yash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:279\u001b[0m, in \u001b[0;36m_check_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[0;32m    269\u001b[0m \n\u001b[0;32m    270\u001b[0m \u001b[39mThis function will raise exception when error occurs.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[39m    return value from API calls\u001b[39;00m\n\u001b[0;32m    277\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    278\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 279\u001b[0m     \u001b[39mraise\u001b[39;00m XGBoostError(py_str(_LIB\u001b[39m.\u001b[39mXGBGetLastError()))\n",
      "\u001b[1;31mXGBoostError\u001b[0m: [17:15:05] C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0fdc6d574b9c0d168-1\\xgboost\\xgboost-ci-windows\\src\\c_api\\c_api.cc:675: DMatrix/Booster has not been initialized or has already been disposed."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import pickle\n",
    "\n",
    "def load_model(file_path):\n",
    "    # Load the pre-trained XGBoost model\n",
    "    with open(file_path, 'rb') as model_file:\n",
    "        loaded_model = pickle.load(model_file)\n",
    "    return loaded_model\n",
    "\n",
    "def preprocess_input(new_input_data):\n",
    "    # Convert new input data to DataFrame\n",
    "    new_input = pd.DataFrame([new_input_data])\n",
    "\n",
    "    # Preprocess the new input data to align with the training data\n",
    "    new_input['Account_Creation_Date'] = pd.to_datetime(new_input['Account_Creation_Date'], errors='coerce')\n",
    "\n",
    "    # Handle errors in datetime conversion\n",
    "    if pd.isnull(new_input['Account_Creation_Date']).any():\n",
    "        print(\"Invalid 'Account_Creation_Date' format. Please ensure it's in YYYY-MM-DD format.\")\n",
    "        return None\n",
    "\n",
    "    new_input['Session_Duration'] = new_input['Session_Duration'].str.extract('(\\d+)').astype(float)\n",
    "    new_input['Time_Between_Transactions'] = new_input['Time_Between_Transactions'].str.extract('(\\d+)').astype(float)\n",
    "    \n",
    "    # Perform one-hot encoding for categorical variables\n",
    "    new_input = pd.get_dummies(new_input)\n",
    "\n",
    "    # Ensure new_input columns match X_train columns\n",
    "    missing_cols = set(X_train.columns) - set(new_input.columns)\n",
    "    for col in missing_cols:\n",
    "        new_input[col] = 0\n",
    "\n",
    "    new_input = new_input[X_train.columns]  # Align columns with X_train\n",
    "    \n",
    "    return new_input\n",
    "\n",
    "\n",
    "# Load the model\n",
    "model_path = 'xgboost_model.pkl'\n",
    "loaded_model = load_model(model_path)\n",
    "\n",
    "# Sample input data\n",
    "new_input_data = {\n",
    "    'Transaction_Amount': [1500],\n",
    "    'User_Account_ID': [104],\n",
    "    'Account_Creation_Date': ['2022-11-15'],\n",
    "    'Payment_Method': ['Credit Card'],\n",
    "    'Billing_Location': ['Bangalore'],\n",
    "    'Shipping_Location': ['Hyderabad'],\n",
    "    'Device_IP_Address': ['192.168.1.40'],\n",
    "    'Session_Duration': ['500 seconds'],\n",
    "    'Frequency_of_Transactions': [7],\n",
    "    'Time_Between_Transactions': ['80 seconds'],\n",
    "    'Unusual_Time_of_Transaction': [0],\n",
    "    'Unusual_Transaction_Amounts': [0],\n",
    "    'IP_Address_History': ['192.168.1.40']\n",
    "}\n",
    "\n",
    "# Load the dataset for column reference\n",
    "file_path = 'transaction_detail.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Preprocess the training data\n",
    "df['Transaction_DateTime'] = pd.to_datetime(df['Transaction_Date'] + ' ' + df['Transaction_Time'])\n",
    "df = df.drop(['Transaction_ID', 'Transaction_Date', 'Transaction_Time'], axis=1)\n",
    "df = pd.get_dummies(df)\n",
    "X_train = df.drop('Fraud_Label', axis=1)  # Features\n",
    "# ... (rest of the training process)\n",
    "\n",
    "# Preprocess new input data\n",
    "new_input = preprocess_input(new_input_data)\n",
    "\n",
    "# Make predictions using the loaded model\n",
    "fraud_prediction = loaded_model.predict(new_input)\n",
    "\n",
    "print(f\"Fraud Prediction: {fraud_prediction}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error preprocessing input data: cannot access local variable 'new_input' where it is not associated with a value\n",
      "Error occurred during prediction.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "\n",
    "# Function to load the XGBoost model\n",
    "\n",
    "\n",
    "def load_model(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'rb') as model_file:\n",
    "            loaded_model = pickle.load(model_file)\n",
    "        return loaded_model\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading the model: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to preprocess input data\n",
    "\n",
    "\n",
    "def preprocess_input(new_input_data):\n",
    "    try:\n",
    "        new_input_data['Account_Creation_Date'] = pd.to_datetime(\n",
    "            new_input_data['Account_Creation_Date'], errors='coerce')\n",
    "        if new_input_data['Account_Creation_Date'].isnull().any():\n",
    "            raise ValueError(\n",
    "                \"Invalid 'Account_Creation_Date' format. Please ensure it's in YYYY-MM-DD format.\")\n",
    "\n",
    "            # Handle errors in datetime conversion\n",
    "        if pd.isnull(new_input['Account_Creation_Date']).any():\n",
    "            print(\n",
    "                \"Invalid 'Account_Creation_Date' format. Please ensure it's in YYYY-MM-DD format.\")\n",
    "            return None\n",
    "\n",
    "        new_input['Session_Duration'] = new_input['Session_Duration'].str.extract(\n",
    "            '(\\d+)').astype(float)\n",
    "        new_input['Time_Between_Transactions'] = new_input['Time_Between_Transactions'].str.extract(\n",
    "            '(\\d+)').astype(float)\n",
    "\n",
    "        # Perform one-hot encoding for categorical variables\n",
    "        new_input = pd.get_dummies(new_input)\n",
    "\n",
    "        # Ensure new_input columns match X_train columns\n",
    "        missing_cols = set(X_train.columns) - set(new_input.columns)\n",
    "        for col in missing_cols:\n",
    "            new_input[col] = 0\n",
    "\n",
    "        new_input = new_input[X_train.columns]  # Align columns with X_train\n",
    "\n",
    "        return new_input\n",
    "    except Exception as e:\n",
    "        print(f\"Error preprocessing input data: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to predict fraud based on new input\n",
    "\n",
    "\n",
    "def predict_fraud(loaded_model, new_input):\n",
    "    try:\n",
    "        preprocessed_input = preprocess_input(new_input)\n",
    "        if preprocessed_input is not None:\n",
    "            fraud_prediction = loaded_model.predict(preprocessed_input)\n",
    "            return fraud_prediction\n",
    "        else:\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error predicting fraud: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# Provide the path to your model file\n",
    "file_path = './xgboost_model.pkl'\n",
    "loaded_model = load_model(file_path)\n",
    "\n",
    "if loaded_model:\n",
    "    new_input_data = {\n",
    "        'Transaction_Amount': [1500],\n",
    "        'User_Account_ID': [104],\n",
    "        'Account_Creation_Date': ['2022-11-15'],\n",
    "        'Payment_Method': ['Credit Card'],\n",
    "        'Billing_Location': ['Bangalore'],\n",
    "        'Shipping_Location': ['Hyderabad'],\n",
    "        'Device_IP_Address': ['192.168.1.40'],\n",
    "        'Session_Duration': ['500 seconds'],\n",
    "        'Frequency_of_Transactions': [7],\n",
    "        'Time_Between_Transactions': ['80 seconds'],\n",
    "        'Unusual_Time_of_Transaction': [0],\n",
    "        'Unusual_Transaction_Amounts': [0],\n",
    "        'IP_Address_History': ['192.168.1.40']\n",
    "    }\n",
    "\n",
    "    fraud_prediction = predict_fraud(loaded_model, new_input_data)\n",
    "    if fraud_prediction is not None:\n",
    "        print(f\"Fraud Prediction: {fraud_prediction}\")\n",
    "    else:\n",
    "        print(\"Error occurred during prediction.\")\n",
    "else:\n",
    "    print(\"Model loading failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
